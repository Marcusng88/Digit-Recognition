{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqYjUo4GuJA_"
      },
      "source": [
        "#RandInitialize.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TxFfooxnDaT",
        "outputId": "77d9f9a5-d6a8-461e-8d9a-871a20036e01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting RandInitialize.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile RandInitialize.py\n",
        "import numpy as np\n",
        "\n",
        "def initialise(a, b):\n",
        "    epsilon = 0.15\n",
        "    c = np.random.rand(a, b + 1) * (\n",
        "      # Randomly initialises values of thetas between [-epsilon, +epsilon]\n",
        "      2 * epsilon) - epsilon\n",
        "    return c\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srnYien4uMe-"
      },
      "source": [
        "#Model.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFhZTUd8nW_z",
        "outputId": "b706f761-8ae3-4edc-c186-30a384baba49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting Model.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile Model.py\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def neural_network(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, lamb):\n",
        "    # Weights are split back to Theta1, Theta2\n",
        "    Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)],\n",
        "                        (hidden_layer_size, input_layer_size + 1))\n",
        "    Theta2 = np.reshape(nn_params[hidden_layer_size * (input_layer_size + 1):],\n",
        "                        (num_labels, hidden_layer_size + 1))\n",
        "\n",
        "    # Forward propagation\n",
        "    m = X.shape[0]\n",
        "    one_matrix = np.ones((m, 1))\n",
        "    X = np.append(one_matrix, X, axis=1)  # Adding bias unit to first layer\n",
        "    a1 = X\n",
        "    z2 = np.dot(X, Theta1.transpose())\n",
        "    a2 = 1 / (1 + np.exp(-z2))  # Activation for second layer\n",
        "    one_matrix = np.ones((m, 1))\n",
        "    a2 = np.append(one_matrix, a2, axis=1)  # Adding bias unit to hidden layer\n",
        "    z3 = np.dot(a2, Theta2.transpose())\n",
        "    a3 = 1 / (1 + np.exp(-z3))  # Activation for third layer\n",
        "\n",
        "    # Changing the y labels into vectors of boolean values.\n",
        "    # For each label between 0 and 9, there will be a vector of length 10\n",
        "    # where the ith element will be 1 if the label equals i\n",
        "    y_vect = np.zeros((m, 10))\n",
        "    for i in range(m):\n",
        "        y_vect[i, int(y[i])] = 1\n",
        "\n",
        "    # Calculating cost function\n",
        "    J = (1 / m) * (np.sum(np.sum(-y_vect * np.log(a3) - (1 - y_vect) * np.log(1 - a3)))) + (lamb / (2 * m)) * (\n",
        "                sum(sum(pow(Theta1[:, 1:], 2))) + sum(sum(pow(Theta2[:, 1:], 2))))\n",
        "\n",
        "    # backprop\n",
        "    Delta3 = a3 - y_vect\n",
        "    Delta2 = np.dot(Delta3, Theta2) * a2 * (1 - a2)\n",
        "    Delta2 = Delta2[:, 1:]\n",
        "\n",
        "    # gradient\n",
        "    Theta1[:, 0] = 0\n",
        "    Theta1_grad = (1 / m) * np.dot(Delta2.transpose(), a1) + (lamb / m) * Theta1\n",
        "    Theta2[:, 0] = 0\n",
        "    Theta2_grad = (1 / m) * np.dot(Delta3.transpose(), a2) + (lamb / m) * Theta2\n",
        "    grad = np.concatenate((Theta1_grad.flatten(), Theta2_grad.flatten()))\n",
        "\n",
        "    return J, grad\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xvn3ULTmuQjg"
      },
      "source": [
        "#Prediction.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3-5Sasqnjkk",
        "outputId": "afddaa32-4113-4adf-8cd5-d2d006453aa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting Prediction.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile Prediction.py\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def predict(Theta1, Theta2, X):\n",
        "    m = X.shape[0]\n",
        "    one_matrix = np.ones((m, 1))\n",
        "    X = np.append(one_matrix, X, axis=1)  # Adding bias unit to first layer\n",
        "    z2 = np.dot(X, Theta1.transpose())\n",
        "    a2 = 1 / (1 + np.exp(-z2))  # Activation for second layer\n",
        "    one_matrix = np.ones((m, 1))\n",
        "    a2 = np.append(one_matrix, a2, axis=1)  # Adding bias unit to hidden layer\n",
        "    z3 = np.dot(a2, Theta2.transpose())\n",
        "    a3 = 1 / (1 + np.exp(-z3))  # Activation for third layer\n",
        "    p = (np.argmax(a3, axis=1))  # Predicting the class on the basis of max value of hypothesis\n",
        "    return p\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9IPScafuTkp"
      },
      "source": [
        "#GUI.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvdpAeM2nonH",
        "outputId": "599477af-b338-4271-ab90-b047b6a3ea88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting GUI.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile GUI.py\n",
        "from tkinter import *\n",
        "import numpy as np\n",
        "from PIL import ImageGrab\n",
        "from Prediction import predict\n",
        "\n",
        "window = Tk()\n",
        "window.title(\"Handwritten digit recognition\")\n",
        "l1 = Label()\n",
        "\n",
        "\n",
        "def MyProject():\n",
        "    global l1\n",
        "\n",
        "    widget = cv\n",
        "    # Setting co-ordinates of canvas\n",
        "    x = window.winfo_rootx() + widget.winfo_x()\n",
        "    y = window.winfo_rooty() + widget.winfo_y()\n",
        "    x1 = x + widget.winfo_width()\n",
        "    y1 = y + widget.winfo_height()\n",
        "\n",
        "    # Image is captured from canvas and is resized to (28 X 28) px\n",
        "    img = ImageGrab.grab().crop((x, y, x1, y1)).resize((28, 28))\n",
        "\n",
        "    # Converting rgb to grayscale image\n",
        "    img = img.convert('L')\n",
        "\n",
        "    # Extracting pixel matrix of image and converting it to a vector of (1, 784)\n",
        "    x = np.asarray(img)\n",
        "    vec = np.zeros((1, 784))\n",
        "    k = 0\n",
        "    for i in range(28):\n",
        "        for j in range(28):\n",
        "            vec[0][k] = x[i][j]\n",
        "            k += 1\n",
        "\n",
        "    # Loading Thetas\n",
        "    Theta1 = np.loadtxt('Theta1.txt')\n",
        "    Theta2 = np.loadtxt('Theta2.txt')\n",
        "\n",
        "    # Calling function for prediction\n",
        "    pred = predict(Theta1, Theta2, vec / 255)\n",
        "\n",
        "    # Displaying the result\n",
        "    l1 = Label(window, text=\"Digit = \" + str(pred[0]), font=('Algerian', 20))\n",
        "    l1.place(x=230, y=420)\n",
        "\n",
        "\n",
        "lastx, lasty = None, None\n",
        "\n",
        "\n",
        "# Clears the canvas\n",
        "def clear_widget():\n",
        "    global cv, l1\n",
        "    cv.delete(\"all\")\n",
        "    l1.destroy()\n",
        "\n",
        "\n",
        "# Activate canvas\n",
        "def event_activation(event):\n",
        "    global lastx, lasty\n",
        "    cv.bind('<B1-Motion>', draw_lines)\n",
        "    lastx, lasty = event.x, event.y\n",
        "\n",
        "\n",
        "# To draw on canvas\n",
        "def draw_lines(event):\n",
        "    global lastx, lasty\n",
        "    x, y = event.x, event.y\n",
        "    cv.create_line((lastx, lasty, x, y), width=30, fill='white', capstyle=ROUND, smooth=TRUE, splinesteps=12)\n",
        "    lastx, lasty = x, y\n",
        "\n",
        "\n",
        "# Label\n",
        "L1 = Label(window, text=\"Handwritten Digit Recoginition\", font=('Algerian', 25), fg=\"blue\")\n",
        "L1.place(x=35, y=10)\n",
        "\n",
        "# Button to clear canvas\n",
        "b1 = Button(window, text=\"1. Clear Canvas\", font=('Algerian', 15), bg=\"orange\", fg=\"black\", command=clear_widget)\n",
        "b1.place(x=120, y=370)\n",
        "\n",
        "# Button to predict digit drawn on canvas\n",
        "b2 = Button(window, text=\"2. Prediction\", font=('Algerian', 15), bg=\"white\", fg=\"red\", command=MyProject)\n",
        "b2.place(x=320, y=370)\n",
        "\n",
        "# Setting properties of canvas\n",
        "cv = Canvas(window, width=350, height=290, bg='black')\n",
        "cv.place(x=120, y=70)\n",
        "\n",
        "cv.bind('<Button-1>', event_activation)\n",
        "window.geometry(\"600x500\")\n",
        "window.mainloop()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "T5GXUlaIkBu4"
      },
      "outputs": [],
      "source": [
        "from scipy.io import loadmat\n",
        "import numpy as np\n",
        "from Model import neural_network\n",
        "from RandInitialize import initialise\n",
        "from Prediction import predict\n",
        "from scipy.optimize import minimize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvKLnWQ1knXH"
      },
      "source": [
        "# Loading mat file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zNfRm6iykpwu"
      },
      "outputs": [],
      "source": [
        "data = loadmat('/Users/PREDATOR/Desktop/Computer_Vision_Projects/Digit-Recognition/mnist-original.mat')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Vz7Emogkt11"
      },
      "source": [
        "# Extracting features from mat file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5k3puMo0kvDo"
      },
      "outputs": [],
      "source": [
        "X = data['data']\n",
        "X = X.transpose()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhjGIy__kyIK"
      },
      "source": [
        "# Normalizing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "6RnFEbc-k0LT"
      },
      "outputs": [],
      "source": [
        "X = X / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biZ3u6lBk2NX"
      },
      "source": [
        "# Extracting labels from mat file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "roAgbS-9k12N"
      },
      "outputs": [],
      "source": [
        "y = data['label']\n",
        "y = y.flatten()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z92FPm5ck5gY"
      },
      "source": [
        "# Splitting data into training set with 60,000 examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "rsPC9fMKk6uc"
      },
      "outputs": [],
      "source": [
        "X_train = X[:60000, :]\n",
        "y_train = y[:60000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9qkM1Fik87s"
      },
      "source": [
        "# Splitting data into testing set with 10,000 examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "QKpSA-YUk_bf"
      },
      "outputs": [],
      "source": [
        "X_test = X[60000:, :]\n",
        "y_test = y[60000:]\n",
        "m = X.shape[0]\n",
        "input_layer_size = 784  # Images are of (28 X 28) px so there will be 784 features\n",
        "hidden_layer_size = 100\n",
        "num_labels = 10  # There are 10 classes [0, 9]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfFCP0qIlEIs"
      },
      "source": [
        "# Randomly initialising Thetas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "PfmHMZNulD2v"
      },
      "outputs": [],
      "source": [
        "initial_Theta1 = initialise(hidden_layer_size, input_layer_size)\n",
        "initial_Theta2 = initialise(num_labels, hidden_layer_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HG7fYP91lIzF"
      },
      "source": [
        "# Unrolling parameters into a single column vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "N5Kr38N4lJIX"
      },
      "outputs": [],
      "source": [
        "initial_nn_params = np.concatenate((initial_Theta1.flatten(), initial_Theta2.flatten()))\n",
        "maxiter = 100\n",
        "lambda_reg = 0.1  # To avoid overfitting\n",
        "myargs = (input_layer_size, hidden_layer_size, num_labels, X_train, y_train, lambda_reg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inh-0v8RlMS7"
      },
      "source": [
        "# Calling minimize function to minimize cost function and to train weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "GNXxIqoflPEp"
      },
      "outputs": [],
      "source": [
        "results = minimize(neural_network, x0=initial_nn_params, args=myargs,\n",
        "          options={'disp': True, 'maxiter': maxiter}, method=\"L-BFGS-B\", jac=True)\n",
        "\n",
        "nn_params = results[\"x\"]  # Trained Theta is extracted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UH_rHUnclRsp"
      },
      "source": [
        "# Weights are split back to Theta1, Theta2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "vFykFCJ6lRdG"
      },
      "outputs": [],
      "source": [
        "Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)], (\n",
        "                              hidden_layer_size, input_layer_size + 1))  # shape = (100, 785)\n",
        "Theta2 = np.reshape(nn_params[hidden_layer_size * (input_layer_size + 1):],\n",
        "                      (num_labels, hidden_layer_size + 1))  # shape = (10, 101)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKS6CKellWjp"
      },
      "source": [
        "# Checking test set accuracy of our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTz3i-1DlXde",
        "outputId": "3f8964ca-0c44-4be9-a0db-516d7eb4739f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Set Accuracy: 97.400000\n"
          ]
        }
      ],
      "source": [
        "pred = predict(Theta1, Theta2, X_test)\n",
        "print('Test Set Accuracy: {:f}'.format((np.mean(pred == y_test) * 100)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3BJ2C_9lZHN"
      },
      "source": [
        "# Checking train set accuracy of our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wwrlxw42laxY",
        "outputId": "817f2b96-5d3c-479b-a2f4-e7e0b6936424"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Set Accuracy: 99.368333\n"
          ]
        }
      ],
      "source": [
        "pred = predict(Theta1, Theta2, X_train)\n",
        "print('Training Set Accuracy: {:f}'.format((np.mean(pred == y_train) * 100)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxGfdFvwlc13"
      },
      "source": [
        "# Evaluating precision of our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9-cjOQZlftk",
        "outputId": "b48421d7-100c-4e66-c43c-745e9a190ff6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision = 0.9936833333333334\n"
          ]
        }
      ],
      "source": [
        "true_positive = 0\n",
        "for i in range(len(pred)):\n",
        "    if pred[i] == y_train[i]:\n",
        "        true_positive += 1\n",
        "false_positive = len(y_train) - true_positive\n",
        "print('Precision =', true_positive/(true_positive + false_positive))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrYzu8lDlho2"
      },
      "source": [
        "# Saving Thetas in .txt file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "_gULCo2kljU1"
      },
      "outputs": [],
      "source": [
        "np.savetxt('Theta1.txt', Theta1, delimiter=' ')\n",
        "np.savetxt('Theta2.txt', Theta2, delimiter=' ')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
